{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#writing ensight Gold binary (comaptible with vtk 8)\n",
    "import numpy as np \n",
    "import os\n",
    "from sys import getsizeof\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputfolder = './1'\n",
    "project_name = 'hex1'\n",
    "outputfolder = './out'\n",
    "\n",
    "alya_id_type = np.int64\n",
    "ensight_id_type = np.int32\n",
    "ensight_float_type = np.float32\n",
    "iterationid_number_of_digits = 6  #how many digits to use for the iteration id in variable files\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def identify_alya_id_type(project_name):\n",
    "    #read he header and see if its int8 or int4\n",
    "    filename = os.path.join(inputfolder,f'{project_name}-LNODS.post.alyabin');\n",
    "    with open(filename, 'rb') as f:\n",
    "        header = read_header(f)\n",
    "        if header['strings'][6] == '4BYTE':\n",
    "            alya_id_type = np.int32\n",
    "        elif header['strings'][6] == '8BYTE':\n",
    "            alya_id_type = np.int64\n",
    "        else:\n",
    "            assert False, f'Alya id type {header[6]} is not supported'\n",
    "    return alya_id_type        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_one_fp90_record(file_object, number_of_elements, datatype):\n",
    "    #fortran stores length with every block, in the beginning and the end\n",
    "    count_read = 0\n",
    "    record = []\n",
    "    while count_read<number_of_elements:\n",
    "        #in case the record is stored as several blocks join them\n",
    "        block_len = np.fromfile(file_object, dtype=np.int32, count=1)\n",
    "        #block_len is in bytes\n",
    "        block = np.fromfile(file_object, dtype=datatype, count=block_len[0]//np.dtype(datatype).itemsize)\n",
    "        block_len = np.fromfile(file_object, dtype=np.int32, count=1)    \n",
    "        count_read = count_read+block_len\n",
    "        record = record + [block]\n",
    "        \n",
    "    return np.concatenate(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_header(file_object):\n",
    "    #a sanity check\n",
    "    assert hasattr(file_object, 'read'), \"read_header: argument is not a file object\"\n",
    "    \n",
    "    ihead = read_one_fp90_record(file_object, 1, np.int32)    #! Header: 1234, int32\n",
    "    assert ihead[0] ==1234, \"Header is not 1234\"\n",
    "    strings = [];\n",
    "    integers = [];\n",
    "    for i in range(0,9):\n",
    "        strings = strings +[read_one_fp90_record(file_object, 8, np.uint8).tostring().decode().strip()]   \n",
    "        #read(ii) strings(1) ! AlyaPost, char8bytes\n",
    "        #read(ii) strings(2) ! Version, char8bytes\n",
    "        #read(ii) strings(3) ! NAME, char8bytes\n",
    "        #read(ii) strings(4) ! SCALA/VECTO, char8bytes\n",
    "        #read(ii) strings(5) ! NELEM/NPOIN/NBOUN, char8bytes\n",
    "        #read(ii) strings(6) ! INTEG/REAL,char8bytes\n",
    "        #read(ii) strings(7) ! 4BYTE/8BYTE, char8bytes -- 4/8 byte integers used subsequently for ids/element type\n",
    "        #read(ii) strings(8) ! SEQUE/PARAL, char8bytes      \n",
    "        #read(ii) strings(9) ! NOFIL/FILTE, char8bytes\n",
    "        \n",
    "    #for i in range(len(strings)):\n",
    "    #    print(strings[i])\n",
    "        \n",
    "        \n",
    "    for i in range(0,3):\n",
    "        integers = integers +[read_one_fp90_record(file_object, 1, np.int32)]   \n",
    "\n",
    "    #for i in range(len(integers)):\n",
    "    #    print(integers[i])\n",
    "\n",
    "    \n",
    "        \n",
    "    #read(ii) integers(1) ! ??? int32\n",
    "    #read(ii) integers(2) ! nelem_total, int32\n",
    "    #read(ii) integers(3) ! # Subdomains, number of parts?\n",
    "    if( strings[1][0:5] != 'V0001' ):\n",
    "        integers = integers +[read_one_fp90_record(file_object, 1, np.int32)]   \n",
    "        #read(ii) integers(4) ! Time step, int32\n",
    "        \n",
    "    reals = read_one_fp90_record(file_object, 1, np.float64)\n",
    "    #read(ii) reals(1)    ! Time, float64\n",
    "\n",
    "    if( strings[1][0:5] == 'V0001' ):\n",
    "        integers[3] = int(reals)  #! floor()?\n",
    "\n",
    "    return {'strings':strings, 'integers':integers, 'reals':reals}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_alya_array(filename, number_of_blocks, datatype):\n",
    "    with open(filename,'rb') as f:\n",
    "        header = read_header(f)\n",
    "        number_of_dimensions = header['integers'][0][0]\n",
    "        number_of_tuples_total = header['integers'][1][0]\n",
    "        time_instant_int = header['integers'][3][0]\n",
    "        time_instant_real = header['reals'][0]\n",
    "        print(f'Reading array: {number_of_dimensions} dim, {number_of_tuples_total} tuples\\n')\n",
    "\n",
    "        tuples = np.zeros((number_of_tuples_total,number_of_dimensions), dtype=datatype)\n",
    "\n",
    "        c = 0;\n",
    "        tuples_per_block = np.zeros(number_of_blocks, dtype=np.int32)\n",
    "        \n",
    "        for i in range(number_of_blocks):\n",
    "            number_of_tuples_in_block = read_one_fp90_record(f, 1, alya_id_type)[0] #stored by alya\n",
    "            tuples_per_block[i] = number_of_tuples_in_block\n",
    "\n",
    "            print(f'Block {i}/{number_of_blocks}: {(number_of_tuples_in_block)} tuples\\n')\n",
    "            tuples_temp = read_one_fp90_record(f, number_of_dimensions*number_of_tuples_in_block, datatype)\n",
    "            \n",
    "            tuples[c:c+number_of_tuples_in_block, :] =                 np.reshape(tuples_temp, (number_of_tuples_in_block,number_of_dimensions))\n",
    "            c = c+number_of_tuples_in_block\n",
    "\n",
    "    return {'tuples':tuples, 'time_real':time_instant_real, 'time_int':time_instant_int, 'tuples_per_block':tuples_per_block};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_alya_variable(variable_name, iteration, number_of_blocks):\n",
    "    field_filename = os.path.join(inputfolder, '%s-%s-%08d.post.alyabin'% (project_name, variable_name, iteration)) \n",
    "    print(field_filename)\n",
    "    \n",
    "    field_dtype = alya_id_type\n",
    "    association = '';\n",
    "    variabletype = ''; #scalar, vector, ...\n",
    "\n",
    "    with open(field_filename,'rb') as f:\n",
    "        header = read_header(f)\n",
    "\n",
    "\n",
    "    \n",
    "    if( header['strings'][5] == 'REAL' ):\n",
    "        field_dtype = np.float64\n",
    "    if( header['strings'][5] == 'INTEG' ):\n",
    "        field_dtype = alya_id_type\n",
    "\n",
    "    if( header['strings'][4] == 'NPOIN' ):\n",
    "        association = 'node'\n",
    "    else:\n",
    "        association = 'element'\n",
    "\n",
    "\n",
    "    if( header['strings'][3] == 'SCALA' ):\n",
    "        variabletype = 'scalar'\n",
    "    elif( header['strings'][3] == 'VECTO' ):\n",
    "        variabletype = 'vector'\n",
    "        print('Reading vectors, this has not been tested yet')\n",
    "    else:\n",
    "        assert False, \"unsupported type of variable\"\n",
    "\n",
    "\n",
    "    if( header['strings'][8] == 'NOFIL' ):\n",
    "        field_data = read_alya_array(field_filename, number_of_blocks, field_dtype)\n",
    "    else: \n",
    "        assert False, \"Filtered types not supported\"\n",
    "        \n",
    "        \n",
    "    return {'values':field_data, 'association':association, 'variabletype':variabletype}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_geometry(project_name, number_of_blocks):\n",
    "    point_coordinates = read_alya_array(os.path.join(inputfolder,f'{project_name}-COORD.post.alyabin'), \\\n",
    "                                        number_of_blocks, np.float64)\n",
    "    element_types = read_alya_array(os.path.join(inputfolder,f'{project_name}-LTYPE.post.alyabin'),  \\\n",
    "                                    number_of_blocks, alya_id_type)\n",
    "    #Read connectivity (indices inside start with 1)\n",
    "    connectivity = read_alya_array(os.path.join(inputfolder,f'{project_name}-LNODS.post.alyabin'),    \\\n",
    "                                   number_of_blocks, alya_id_type)\n",
    "\n",
    "    #elements have ids local to each block, tranform them to global ids\n",
    "    a = connectivity['tuples_per_block'][0]\n",
    "    npts =  point_coordinates['tuples_per_block'][0]\n",
    "    for i in range(1,connectivity['tuples_per_block'].shape[0]): #for each block, skip 0\n",
    "        b = a + connectivity['tuples_per_block'][i]\n",
    "        connectivity['tuples'][a:b,:] = connectivity['tuples'][a:b,:] + npts\n",
    "        a = b\n",
    "        npts = npts + point_coordinates['tuples_per_block'][i]\n",
    "        \n",
    "        \n",
    "    #assume all elements are the same\n",
    "    element_type = b'hexa8';\n",
    "    if element_types['tuples'][0] == 37: #alya hex08 element\n",
    "        element_type = b'hexa8';\n",
    "    elif element_types['tuples'][0] == 30: #alya tet04 element\n",
    "        element_type = b'tetra4';\n",
    "        \n",
    "    #geometry ensight\n",
    "    with open(os.path.join(outputfolder,f'{project_name}.ensi.geo'),'wb') as f:\n",
    "        f.write(b'C Binary'.ljust(80))\n",
    "        f.write(b'description line 1'.ljust(80))\n",
    "        f.write(b'description line 2'.ljust(80))\n",
    "        f.write(b'node id given'.ljust(80))\n",
    "        f.write(b'element id given'.ljust(80))\n",
    "        f.write(b'part'.ljust(80))\n",
    "        f.write(np.array([1], dtype=ensight_id_type))   #int\n",
    "        f.write(b'description line 1'.ljust(80))\n",
    "        f.write(b'coordinates'.ljust(80))\n",
    "\n",
    "        number_of_points = point_coordinates['tuples'].shape[0]\n",
    "        f.write(np.array([number_of_points], dtype=ensight_id_type))   #int\n",
    "        f.write(np.arange(1,number_of_points+1, dtype=ensight_id_type))\n",
    "        f.write( point_coordinates['tuples'][:,0].ravel().astype(ensight_float_type) )  #x coord\n",
    "        f.write( point_coordinates['tuples'][:,1].ravel().astype(ensight_float_type) )  #y coord\n",
    "        f.write( point_coordinates['tuples'][:,2].ravel().astype(ensight_float_type) )  #z coord\n",
    "\n",
    "        f.write(element_type.ljust(80))  #tetra4 or hexa8\n",
    "        number_of_elements = connectivity['tuples'].shape[0]\n",
    "        f.write(np.array([number_of_elements], dtype=ensight_id_type))   #int\n",
    "        f.write(np.arange(1,number_of_elements+1, dtype=ensight_id_type))\n",
    "        f.write(connectivity['tuples'].ravel().astype(ensight_id_type))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_variable(varname, iteration, number_of_blocks):\n",
    "    data = read_alya_variable(varname, iteration, number_of_blocks)\n",
    "\n",
    "    \n",
    "    #variable ensight\n",
    "    fmt = '%s.ensi.%s-'+f'%0{iterationid_number_of_digits}d';\n",
    "    with open( os.path.join(outputfolder, fmt % (project_name, varname, iteration+1)),'wb') as f:\n",
    "        f.write(b'description line 1'.ljust(80))\n",
    "        f.write(b'part'.ljust(80))\n",
    "        f.write(np.array([1], dtype=ensight_id_type))   #int\n",
    "        f.write(b'coordinates'.ljust(80))\n",
    "\n",
    "        if data['variabletype']=='scalar':\n",
    "            f.write( data['values']['tuples'].ravel().astype(ensight_float_type) )  #z coord    \n",
    "        elif data['variabletype']=='vector':\n",
    "            #data has coordinates in the order [[x,y,z],[x,y,z],...]\n",
    "            #expected order of coordinates\n",
    "            #vx_n1 vx_n2 ... vx_nn nn floats\n",
    "            #vy_n1 vy_n2 ... vy_nn nn floats\n",
    "            #vz_n1 vz_n2 ... vz_nn nn floats\n",
    "            #Rearrange the  matrix\n",
    "            f.write( data['values']['tuples'].ravel(order='F').astype(ensight_float_type) )  #z coord    \n",
    "        else:\n",
    "            assert False, f\"Unknown varibale type: {data['variabletype']}\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    return {'time_real':data['values']['time_real'], 'time_int':data['values']['time_int'],             'variable_type':data['variabletype'], 'variable_association':data['association']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Alya id type <class 'numpy.int32'>\n"
     ]
    }
   ],
   "source": [
    "#identify id type\n",
    "alya_id_type = identify_alya_id_type(project_name)\n",
    "print(f'Using Alya id type {alya_id_type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the partitioning info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     1, 514551,  95030,      0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the partitioning info\n",
    "partition_filename = os.path.join(inputfolder,f'{project_name}.post.alyapar')\n",
    "with open(partition_filename) as f:\n",
    "    partitions = np.fromstring(f.read(), dtype=alya_id_type, sep=' ')\n",
    "\n",
    "#describes the mesh partitions\n",
    "#partition_id,  NumberOfElementsInPartition,  NumberOfPointsInPartition, NumberOfBoundariesInPartition\n",
    "partitions = np.reshape(partitions[1:],(partitions[0],4))\n",
    "partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this script does not handle boundaries yet\n",
    "assert (partitions[:,3]==0).all(),  'this script does not handle boundaries yet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>filename</th>\n",
       "      <th>iteration</th>\n",
       "      <th>time_int</th>\n",
       "      <th>time_real</th>\n",
       "      <th>variabletype</th>\n",
       "      <th>association</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INTRA</td>\n",
       "      <td>hex1-INTRA-00000000.post.alyabin</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INTRA</td>\n",
       "      <td>hex1-INTRA-00000050.post.alyabin</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTRA</td>\n",
       "      <td>hex1-INTRA-00000100.post.alyabin</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   field                          filename  iteration  time_int  time_real  \\\n",
       "0  INTRA  hex1-INTRA-00000000.post.alyabin          0         0          0   \n",
       "1  INTRA  hex1-INTRA-00000050.post.alyabin         50         0          0   \n",
       "2  INTRA  hex1-INTRA-00000100.post.alyabin        100         0          0   \n",
       "\n",
       "  variabletype association  \n",
       "0                           \n",
       "1                           \n",
       "2                           "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parse the filelist of the fields\n",
    "with open(os.path.join(inputfolder, f'{project_name}.post.alyafil'),'r') as f:\n",
    "    field_filelist = f.read().splitlines()\n",
    "    \n",
    "#remove spaces and empty lines\n",
    "field_filelist = [x.strip() for x in field_filelist if x.strip()!='']\n",
    "\n",
    "#extract array names and iteration numbers \n",
    "fields = []\n",
    "iteration_numbers = []\n",
    "for filename in field_filelist:\n",
    "    s1 = filename.split('-');\n",
    "    fields = fields + [s1[1]]\n",
    "    iteration_numbers =  iteration_numbers + [ int(s1[2].split('.')[0]) ] #this will be long in python 3\n",
    "    \n",
    "variable_info = pandas.DataFrame({'field':fields, 'iteration':iteration_numbers,'filename':field_filelist})\n",
    "variable_info['time_int'] = 0\n",
    "variable_info['time_real'] = 0\n",
    "variable_info['variabletype']=''\n",
    "variable_info['association']=''\n",
    "variable_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unknown stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#god knows what are these\n",
    "#LNINV = read_alya_array(os.path.join(inputfolder,f'{project_name}-LNINV.post.alyabin'), \\\n",
    "#                                number_of_blocks, alya_id_type)\n",
    "#LELCH = read_alya_array(os.path.join(inputfolder,f'{project_name}-LELCH.post.alyabin'), \\\n",
    "#                                number_of_blocks, alya_id_type)\n",
    "#LEINV = read_alya_array(os.path.join(inputfolder,f'{project_name}-LEINV.post.alyabin'), \\\n",
    "#                                number_of_blocks, alya_id_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write geometry and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading array: 3 dim, 95030 tuples\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-35d63ccf6952>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#blocks are mesh partitions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnumber_of_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mwrite_geometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-dcb8b989db7e>\u001b[0m in \u001b[0;36mwrite_geometry\u001b[0;34m(project_name, number_of_blocks)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrite_geometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpoint_coordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_alya_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputfolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{project_name}-COORD.post.alyabin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                         \u001b[0mnumber_of_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0melement_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_alya_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputfolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{project_name}-LTYPE.post.alyabin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                      \u001b[0mnumber_of_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malya_id_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#Read connectivity (indices inside start with 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mconnectivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_alya_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputfolder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{project_name}-LNODS.post.alyabin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m                                       \u001b[0mnumber_of_blocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malya_id_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-1bfece7d7acc>\u001b[0m in \u001b[0;36mread_alya_array\u001b[0;34m(filename, number_of_blocks, datatype)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber_of_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mnumber_of_tuples_in_block\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_one_fp90_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malya_id_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#stored by alya\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mtuples_per_block\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumber_of_tuples_in_block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "#blocks are mesh partitions\n",
    "number_of_blocks = partitions.shape[0]\n",
    "write_geometry(project_name, number_of_blocks)\n",
    "\n",
    "\n",
    "for index, row in variable_info.iterrows():\n",
    "    info = write_variable(row.field, row.iteration, number_of_blocks)\n",
    "    variable_info.loc[index, 'time_real'] = info['time_real']\n",
    "    variable_info.loc[index, 'time_int']= info['time_int']\n",
    "    variable_info.loc[index, 'variabletype'] = info['variable_type']\n",
    "    variable_info.loc[index, 'association'] = info['variable_association']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write ensight case file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "case_file = f'{project_name}.ensi.case'\n",
    "with open(os.path.join(outputfolder, case_file), 'w') as f:\n",
    "    f.write('# Converted from Alya\\n')\n",
    "    f.write('# Ensight Gold Format\\n')\n",
    "    f.write('#\\n')\n",
    "    f.write(f'# Problem name: {project_name}\\n')\n",
    "    f.write('FORMAT\\n')\n",
    "    f.write('type: ensight gold\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('GEOMETRY\\n')\n",
    "    f.write(f'model: 1 {project_name}.ensi.geo\\n')\n",
    "    f.write('\\n')\n",
    "    f.write('VARIABLE\\n')\n",
    "    \n",
    "    variables = variable_info.field.unique();\n",
    "    \n",
    "    for varname in variables:\n",
    "        df = variable_info[variable_info.field==varname].loc[0] #get one rectrod with this varibale\n",
    "        line = f'{df.variabletype} per {df.association}: 1 {varname} {project_name}.ensi.{varname}-'+\\\n",
    "            '*'*iterationid_number_of_digits+'\\n'       \n",
    "        f.write(line)\n",
    "        \n",
    "    #this should be the same for all variables as I'm saving only one time series\n",
    "    df_one_var =  variable_info[variable_info.field==variable_info.loc[0,'field']].sort_values(by='iteration');\n",
    "    \n",
    "    \n",
    "    number_of_timesteps = variable_info[variable_info.field==variable_info.loc[0,'field']].shape[0]\n",
    "    \n",
    "    filename_increment = 0\n",
    "    if df_one_var.shape[0]>1:\n",
    "        filename_increment = df_one_var.loc[1,'iteration']-df_one_var.loc[0,'iteration']\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('TIME\\n')\n",
    "    f.write('time set: 1\\n')\n",
    "    f.write(f'number of steps: {number_of_timesteps}\\n')\n",
    "    f.write(f'filename start number: {df_one_var.iteration.min()+1}\\n')\n",
    "    f.write(f'filename increment: {filename_increment}\\n') \n",
    "    f.write('time values:\\n')\n",
    "    f.write(str(df_one_var.time_real.as_matrix())[1:-1]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.dtype(np.int32)\n",
    "b= np.array(a.name)\n",
    "c = np.dtype(str(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int32"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
